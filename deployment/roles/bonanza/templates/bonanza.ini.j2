[app:main]
use = egg:bonanza

pyramid.reload_templates = true
pyramid.debug_authorization = false
pyramid.debug_notfound = false
pyramid.debug_routematch = false
pyramid.debug_templates = false
pyramid.default_locale_name = en
pyramid.includes = pyramid_tm

sqlalchemy.url = postgres://{{ bonanza_database.user }}:{{ bonanza_database.password }}@{{ bonanza_database.host }}/{{ bonanza_database.name }}
bonanza.debug = false

jinja2.directories =
    bonanza:templates
jinja2.filters =
    model_url = pyramid_jinja2.filters:model_url_filter
    route_url = pyramid_jinja2.filters:route_url_filter
    static_url = pyramid_jinja2.filters:static_url_filter
jinja2.autoescape = False
jinja2.cache_size = 0

scss.asset_path = bonanza:assets/scss

[server:main]
use = egg:waitress#main
host = 0.0.0.0
port = 6543

[pshell]
setup = bonanza.scripts.shell.setup

[task]
kombu.broker_url = amqp://{{ rabbitmq.user.name }}:{{ rabbitmq.user.password }}@{{ rabbitmq.host }}/
kombu.serializer = json
kombu.prefetch_count = 10
task.thread_name = {task_name}.{class_name}-{worker_number}

[task:produce_subdomains]
region_file = %(here)s/data/cl_regions.json

task.class = bonanza.tasks.craigslist:UrlProducerTask
task.workers = 1
task.schedule =
    freq = daily
    byhour = 4
    byminute = 0
    bysecond = 0
task.exchanges = requests, listings
task.queues =
    requests = requests-craigslist-subdomain

[task:request_subdomain]
task.class = bonanza.tasks.craigslist:JsonSearchTask
task.rate = 1.0  ; per second
task.workers = 4
task.exchanges = requests, listings
task.queues =
    requests = requests-craigslist-subdomain
    geocluster_requests = requests-craigslist-geocluster
    listings = listings-craigslist

[task:request_geocluster]
task.class = bonanza.tasks.craigslist:JsonSearchTask
task.workers = 2
task.rate = 0.25
task.exchanges = requests, listings
task.queues =
    requests = requests-craigslist-geocluster
    listings = listings-craigslist

[task:process_craigslist_listings]
task.class = bonanza.tasks.craigslist:ListingProcessorTask
task.workers = 4
task.queues =
    listings = listings-craigslist

[task:produce_homepath_searches]
task.class = bonanza.tasks.homepath:UrlProducerTask
task.workers = 1
task.schedule =
    freq = weekly
    byweekday = tuesday, friday
    byhour = 7
    byminute = 0
    bysecond = 0
task.exchanges = requests, listings
task.queues =
    requests = requests-homepath-results

[task:request_homepath_results]
task.class = bonanza.tasks.homepath:JsonSearchTask
task.rate = 1.0  ; per second
task.workers = 4
task.exchanges = requests, listings
task.queues =
    requests = requests-homepath-results
    listings = listings-homepath

[task:process_homepath_listings]
task.class = bonanza.tasks.homepath:ListingProcessorTask
task.workers = 4
task.queues =
    listings = listings-homepath

[exchange:requests]
type = topic
durable = true

[exchange:listings]
type = topic
durable = true

[queue:requests-craigslist-subdomain]
exchange = requests
routing_key = requests.craigslist.subdomain

[queue:requests-craigslist-geocluster]
exchange = requests
routing_key = requests.craigslist.geocluster

[queue:listings-craigslist]
exchange = listings
routing_key = listings.craigslist

[queue:requests-homepath-results]
exchange = requests
routing_key = requests.homepath.results

[queue:listings-homepath]
exchange = listings
routing_key = listings.homepath

[alembic]
script_location = migrations
sqlalchemy.url = postgres://{{ bonanza_database.user }}:{{ bonanza_database.password }}@{{ bonanza_database.host }}/{{ bonanza_database.name }}
file_template = %%(slug)s-%%(rev)s
exclude_tables = spatial_ref_sys

# Begin logging configuration

[loggers]
keys = root, bonanza, bonanza_tasks, sqlalchemy, alembic, requests

[handlers]
keys = console, sentry

[formatters]
keys = generic

[logger_root]
level = DEBUG
handlers = console, sentry

[logger_requests]
level = WARN
handlers =
qualname = requests

[logger_bonanza]
level = INFO
handlers =
qualname = bonanza

[logger_bonanza_tasks]
level = DEBUG
handlers =
qualname = bonanza.tasks

[logger_sqlalchemy]
level = WARN
handlers =
qualname = sqlalchemy.engine
# "level = INFO" logs SQL queries.
# "level = DEBUG" logs SQL queries and results.
# "level = WARN" logs neither.  (Recommended for production systems.)

[logger_alembic]
level = INFO
handlers =
qualname = alembic

[handler_console]
class = StreamHandler
args = (sys.stderr,)
level = NOTSET
formatter = generic

[handler_sentry]
class = raven.handlers.logging.SentryHandler
args = ('http://{{ sentry.project.api_key }}@{{ sentry.host }}:{{ sentry.port }}/{{ sentry.project.id }}',)
level = WARNING
formatter = generic

[formatter_generic]
format = %(asctime)s %(levelname)-10.8s [%(name)s][%(threadName)s] %(message)s

# End logging configuration
